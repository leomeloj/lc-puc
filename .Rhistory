df = read.table('corpus.txt',sep="|",header=T)
# If you want to test on just 1000 records using df.1000 created below
idx.1000 = sample(1:nrow(df),1000)
df.1000 = df[idx.1000,]
# Grab just the texts, so you can load them in the Corpus
df.texts = as.data.frame(df[,ncol(df)])
colnames(df.texts) = 'FullText'
# Remove non-ascii characters
df.texts.clean = as.data.frame(iconv(df.texts$FullText, "latin1", "ASCII", sub=""))
colnames(df.texts.clean) = 'FullText'
# Load using the tm library
library(tm)
docs <- Corpus(DataframeSource(df.texts.clean))
# Strip extra whitespace
docs <- tm_map(docs, stripWhitespace)
bankA.idx = which(sapply(df$FullText,function(x) grepl("BankA",x)))
bankB.idx = which(sapply(df$FullText,function(x) grepl("BankB",x)))
bankC.idx = which(sapply(df$FullText,function(x) grepl("BankC",x)))
bankD.idx = which(sapply(df$FullText,function(x) grepl("BankD",x)))
# This turns out to be too slow
# Add the metadata
# This takes a bit to run
# You can add more here
#for (i in 1:nrow(df)) {
#  meta(docs[[i]],"MediaType") = df$MediaType[i]
#  meta(docs[[i]],"Year") = df$Year[i]
#  if (grepl("BankA",df$FullText[i])) {
#    meta(docs[[i]],"BankA") = T
#  } else {
#    meta(docs[[i]],"BankA") = F
#  }
#  if (grepl("BankB",df$FullText[i])) {
#    meta(docs[[i]],"BankB") = T
#  } else {
#    meta(docs[[i]],"BankB") = F
#  }
#}
#bankA.idx <- meta(docs, "BankA") == T
bankA.docs = docs[bankA.idx]
bankB.docs = docs[bankB.idx]
bankC.docs = docs[bankC.idx]
bankD.docs = docs[bankD.idx]
summary(docs)
docs <- tm_map(docs, removePunctuation)
install.packages("shiny")
library(shiny)
runExample("01_hello")
library("twitteR")
library("tm")
args = commandArgs(trailingOnly=TRUE)
stop()
print(hashtag + ".txt")
hashtag = "#PEC241"
print(hashtag + ".txt")
print(c(hashtag, ".txt"))
print(cbind(hashtag, ".txt"))
print(paste(hashtag, ".txt"))
print(paste(hashtag,".txt"))
print(paste(hashtag,".txt", sep = ""))
print(str_replace_all(paste(hashtag,".txt", sep = ""), "#", ""))
print(str_replace(paste(hashtag,".txt", sep = ""), "#", ""))
library("tm")
library("twitteR")
library("string")
library("stringr")
print(str_replace_all(paste(hashtag,".txt", sep = ""), "#", ""))
print(str_replace_all(paste(hashtag,".txt", sep = ""), "#", ""))
consumer_key <- 'fNzv8UHijytruZ5K12wR8BukT'
consumer_secret <- '62gJKnpIumCsD4od8ICj0XiPocssjhUm6QIsqeyS4QKylKtE7B'
access_token <- '720060230617427969-Jc8EplKKJ0GqcGPwLqTEm2sApvKvv4U'
access_secret <- 'FkARP3SI3KvQtQ25XOtd8WAtR7hLfbKElKcGE9nzlQsAG'
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
tweets <- searchTwitter("#PEC255", n=5000, lang = "pt")
tweets <- searchTwitter("#PEC251", n=5000, lang = "pt")
tweets <- searchTwitter("#PEC55", n=5000, lang = "pt")
caminho.arquivo = paste("F:/analisador_sentimentos/", arquivo)
arquivo = paste("tweets/", str_replace_all(paste(hashtag,".csv", sep = ""), "#", ""))
caminho.arquivo = paste("F:/analisador_sentimentos/", arquivo)
print(caminho.arquivo)
caminho.arquivo = paste("F:/analisador_sentimentos/", arquivo, sep = "")
print(caminho.arquivo)
arquivo = paste("tweets/", str_replace_all(paste(hashtag,".csv", sep = ""), "#", ""), sep = "")
caminho.arquivo = paste("F:/analisador_sentimentos/", arquivo, sep = "")
print(caminho.arquivo)
caminho = "F:/analisador_sentimentos"
caminho.arquivo = paste(caminho, arquivo, sep = "")
print(caminho.arquivo)
arquivo = paste("tweets/", str_replace_all(paste(hashtag,".csv", sep = ""), "#", ""), sep = "")
caminho.arquivo = paste(caminho, arquivo, sep = "")
print(caminho.arquivo)
caminho = "F:/analisador_sentimentos/"
setwd(caminho)
caminho.arquivo = paste(caminho, arquivo, sep = "")
print(caminho.arquivo)
comando = paste("java –jar lematizador", caminho.arquivo, "nf")
print(comando)
comando = paste("java –jar ", caminho, "/LematizadorV2a/",  "lematizador.jar ", caminho.arquivo, " nf", sep="")
print(comando)
comando = paste("java –jar ", caminho, "LematizadorV2a/",  "lematizador.jar ", caminho.arquivo, " nf", sep="")
print(comando)
arquivo.csv = paste("tweets/", str_replace_all(paste(hashtag,".csv", sep = ""), "#", ""), sep = "")
arquivo.txt = paste("tweets/", str_replace_all(paste(hashtag,".txt", sep = ""), "#", ""), sep = "")
print(arquivo.txt)
caminho.arquivo = paste(caminho, arquivo.txt, sep = "")
comando = paste("java –jar ", caminho, "LematizadorV2a/",  "lematizador.jar ", caminho.arquivo, " nf", sep="")
print(comando)
system("cd F:/analisador_sentimentos/LematizadorV2a/")
